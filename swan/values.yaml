jupyterhub:
  singleuser:
    uid: 0
    fsGid: 0
    storage:
      type: none
    image:
      name: "gitlab-registry.cern.ch/swan/docker-images/systemuser"
      tag: "v5.6.1"
      pullPolicy: "Always"
    cloudMetadata:
      enabled: true
    networkPolicy:
      enabled: false
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: traefik
      traefik.ingress.kubernetes.io/frontend-entry-points: http, https
      traefik.ingress.kubernetes.io/redirect-entry-point: https
    # tls-cert is commented out, using lets encrypt certificates
    #tls:
    #  - secretName: swan-tls-cert
    # placeholder for hostname
    hosts:
  proxy:
    service:
      type: ClusterIP
    chp:
      image:
        name: "jupyterhub/configurable-http-proxy"
        tag: "4.2.0"
        pullPolicy: "IfNotPresent"
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
    # placeholder for hub secret token
    secretToken:
  hub:
    fsGid: 0
    containerSecurityContext:
      runAsUser: 0
      runAsGroup: 0
    deploymentStrategy:
      type: RollingUpdate
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
    livenessProbe:
      enabled: false
    readinessProbe:
      enabled: false
    image:
      name: "gitlab-registry.cern.ch/swan/docker-images/jupyterhub"
      tag: "v1.13"
      pullPolicy: "Always"
    extraVolumeMounts:
      - name: swan-jh
        mountPath: /srv/jupyterhub/options_form_config.json
        subPath: options_form_config.json
      - name: swan-jh
        mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/1_swan_config.py
        subPath: swan_config.py
      - name: swan-jh
        mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/2_swan_spark_config.py
        subPath: swan_spark_config.py
      - name: swan-secrets
        mountPath: /srv/jupyterhub/private/eos.cred
        subPath: eos.cred
      - name: swan-secrets
        mountPath: /srv/jupyterhub/private/hadoop.cred
        subPath: hadoop.cred
      - name: swan-secrets
        mountPath: /srv/jupyterhub/private/sparkk8s.cred
        subPath: sparkk8s.cred
      - name: swan-cull-scripts
        mountPath: /srv/jupyterhub/culler/check_ticket.sh
        subPath: cull_check_ticket.sh
      - name: swan-cull-scripts
        mountPath: /srv/jupyterhub/culler/delete_ticket.sh
        subPath: cull_delete_ticket.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/eos_token.sh
        subPath: eos_token.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/hadoop_token.sh
        subPath: hadoop_token.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/webhdfs_token.sh
        subPath: webhdfs_token.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/sparkk8s_token.sh
        subPath: sparkk8s_token.sh
      - name: cvmfs-sft-cern-ch
        mountPath: /cvmfs/sft.cern.ch
    extraVolumes:
      - name: cvmfs-sft-cern-ch
        persistentVolumeClaim:
          claimName: cvmfs-sft-cern-ch-pvc
      - name: swan-jh
        configMap:
          name: swan-scripts
          items:
          - key: options_form_config.json
            path: options_form_config.json
          - key: swan_config.py
            path: swan_config.py
          - key: swan_spark_config.py
            path: swan_spark_config.py
      - name: swan-cull-scripts
        configMap:
          name: swan-scripts
          items:
          - key: cull_check_ticket.sh
            path: cull_check_ticket.sh
          - key: cull_delete_ticket.sh
            path: cull_delete_ticket.sh
          defaultMode: 356 # 0544 perm
      - name: swan-tokens-scripts
        configMap:
          name: swan-scripts-env-prod
          items:
          - key: hadoop_token.sh
            path: hadoop_token.sh
          - key: webhdfs_token.sh
            path: webhdfs_token.sh
          - key: eos_token.sh
            path: eos_token.sh
          - key: sparkk8s_token.sh
            path: sparkk8s_token.sh
          defaultMode: 356 # 0544 perm
      - name: swan-secrets
        secret:
          secretName: swan
          items:
          - key: eos.cred
            path: eos.cred
          - key: hadoop.cred
            path: hadoop.cred
          - key: sparkk8s.cred
            path: sparkk8s.cred
    config:
      KeyCloakAuthenticator:
        oidc_issuer: https://auth.cern.ch/auth/realms/cern
        admin_role: swan-admins
        scope:
          - profile
          - email
          - offline_access
        exchange_tokens:
          - eos-service
          - cernbox-service
        logout_redirect_uri: https://cern.ch/swan
        auto_login: True
        username_key: preferred_username
        client_id: # placeholder, check secrets
        client_secret: # placeholder, check secrets
        oauth_callback_url: # placeholder, check secrets
      SwanSpawner:
        options_form_config: /srv/jupyterhub/options_form_config.json
        # Give notebook 45s to start a webserver and max 60s for whole spawn process
        http_timeout: 45
        start_timeout: 60
        consecutive_failure_limit: 0
      SwanKubeSpawner:
        # Required for swan systemuser.sh
        # FIXME clean with new image?
        cmd: None
        # set home directory to EOS
        local_home: False
      SpawnHandlersConfigs:
        # disable some defaults of swanspawner that do now work for kube-spawner
        # FIXME remove this from the spawner once we support only k8s
        metrics_on: False
        local_home: True
      JupyterHub:
        authenticator_class: keycloakauthenticator.KeyCloakAuthenticator
        spawner_class: swanspawner.SwanKubeSpawner
        cleanup_servers: False
        tornado_settings:
          # currently we customize spawnhandler to stay in form before redirecting the user, as upstream does
          # FIXME remove once we remove the the metrics from the spawn
          slow_spawn_timeout: 15
        allow_named_servers: False
    extraConfig:
      00-authConf: |
        def pre_spawn_hook(authenticator, spawner, auth_state):
          spawner.environment['ACCESS_TOKEN'] = auth_state['exchanged_tokens']['eos-service']
          spawner.environment['OAUTH_INSPECTION_ENDPOINT'] = authenticator.userdata_url.replace('https://', '')
          spawner.user_uid = str(str(auth_state['oauth_user']['cern_uid'])) # k8s only supports values as strings!
          decoded_token = authenticator._decode_token(auth_state['access_token'])
          spawner.user_roles = authenticator.claim_roles_key(authenticator, decoded_token)
        c.KeyCloakAuthenticator.pre_spawn_hook = pre_spawn_hook
      # TODO delete this once we upgrade to newer upstream (which loads files from this path automatically)
      01-swanConf: |
        exec(open('/usr/local/etc/jupyterhub/jupyterhub_config.d/1_swan_config.py').read())
      02-spawnError: |
        SPAWN_ERROR_MESSAGE = """SWAN could not start a session for your user, please try again. If the problem persists, please check:
        <ul>
            <li>Do you have a CERNBox account? If not, click <a href="https://cernbox.cern.ch" target="_blank">here</a>.</li>
            <li>Is there a problem with the service? Find information <a href="https://cern.service-now.com/service-portal?id=service_status_board" target="_blank">here</a>.</li>
            <li>If none of the options apply, please open a <a href="https://cern.service-now.com/service-portal?id=functional_element&name=swan" target="_blank">Support Ticket</a>.</li>
        </ul>"""

        # SWAN@CERN error message
        c.SpawnHandlersConfigs.spawn_error_message = SPAWN_ERROR_MESSAGE
      # TODO move this into separate chart
      # TODO delete this once we upgrade to newer upstream (which loads files from this path automatically)
      10-sparkConf: |
        exec(open('/usr/local/etc/jupyterhub/jupyterhub_config.d/2_swan_spark_config.py').read()) 
        c.SwanKubeSpawner.modify_pod_hook = spark_modify_pod_hook
    extraEnv:
      # placeholder for hub auth state cryptographic key
      JUPYTERHUB_CRYPT_KEY:
    db:
      type: postgres
      # placeholder for postgres connection url
      url: 
      # placeholder for postgres password
      password:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/path: /hub/metrics
    networkPolicy:
      enabled: false
    # placeholder for hub cookieSecret
    # when empty, it generates a new randomly
    cookieSecret:
  rbac:
    enabled: true
  scheduling:
    userScheduler:
      enabled: false
    podPriority:
      enabled: false
  prePuller:
    hook:
      enabled: true
    continuous:
      enabled: false
  debug:
    enabled: true
  # disable upstream cull, but enable custom one
  cull:
    enabled: false
  custom:
    cull:
      enabled: true
      period: 600
      checkEosAuth: true
    cvmfs:
      storageProvisioner: csi-cvmfsplugin
      repositories:
        - sft.cern.ch
        - sft-nightlies.cern.ch
        - alice.cern.ch
        - alice-ocdb.cern.ch
        - alice-nightlies.cern.ch
        - atlas.cern.ch
        - atlas-condb.cern.ch
        - atlas-nightlies.cern.ch
        - cms.cern.ch
        - cms-ib.cern.ch
        - cms-bril.cern.ch
        - lhcb.cern.ch
        - lhcb-condb.cern.ch
        - lhcbdev.cern.ch
        - fcc.cern.ch
        - geant4.cern.ch
        - clicbp.cern.ch
        - ams.cern.ch
        - compass.cern.ch
        - compass-condb.cern.ch
        - na62.cern.ch
        - ganga.cern.ch
        - na61.cern.ch
        - projects.cern.ch
        - alpha.cern.ch
        - cvmfs-config.cern.ch
        - sw.hsf.org
      prefetcher:
        enabled: false
        image:
          name: "gitlab-registry.cern.ch/swan/docker-images/cvmfs-prefetcher"
          tag: "v1.1"
# placeholders for swan credentials
swan:
  secrets:
    eos:
      cred:
    hadoop:
      cred:
    sparkk8s:
      cred:
    ingress:
      cert:
      key:
      
#
# Decide which client to use for accessing EOS
# - daemonSet deploys eosxd pods exposing `/eos` path on the host.
#     Other pods can access `/eos` bind-mounting from the host.
# - CSI driver configures a cluster-wide storage driver for EOS.
#     Access to EOS is provided by persistnt volume claims.
#
# By setting both to false, no eosxd client pods will be deployed
#   and access to EOS will not be possible.
#
# Warning: It is discouraged to enable both at the same time.
#
eosClient:
  daemonSet: true
  csiDriver: false

#
# Decide which client to use for accessing CVMFS
# - daemonSet deploys cvmfs pods exposing `/cvmfs` path on the host.
#     Other pods can access `/cvmfs` bind-mounting from the host.
# - CSI driver configures a cluster-wide storage driver for CVMFS.
#     Access to CVMFS is provided by persistnt volume claims.
#
# By setting both to false, no cvmfs client pods will be deployed
#   and access to CVMFS will not be possible.
#
# Warning: It is discouraged to enable both at the same time.
#
cvmfsClient:
  daemonSet: true
  csiDriver: false