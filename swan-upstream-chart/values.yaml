jupyterhub:
  singleuser:
    uid: 0
    fsGid: 0
    storage:
      type: none
    image:
      name: "gitlab-registry.cern.ch/swan/docker-images/systemuser"
      tag: "v5.6.1"
      pullPolicy: "Always"
    cloudMetadata:
      enabled: true
    networkPolicy:
      enabled: false
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: traefik
      traefik.ingress.kubernetes.io/frontend-entry-points: http, https
      traefik.ingress.kubernetes.io/redirect-entry-point: https
    # tls-cert is commented out, using lets encrypt certificates
    #tls:
    #  - secretName: swan-tls-cert
    # placeholder for hostname
    hosts:
  proxy:
    service:
      type: ClusterIP
    chp:
      image:
        name: "jupyterhub/configurable-http-proxy"
        tag: "4.2.0"
        pullPolicy: "IfNotPresent"
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
    # placeholder for hub secret token
    secretToken:
  hub:
    fsGid: 0
    containerSecurityContext:
      runAsUser: 0
      runAsGroup: 0
    deploymentStrategy:
      type: RollingUpdate
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
    livenessProbe:
      enabled: false
    readinessProbe:
      enabled: false
    image:
      name: "gitlab-registry.cern.ch/swan/docker-images/jupyterhub"
      tag: "v1.12"
      pullPolicy: "Always"
    extraVolumeMounts:
      - name: swan-jh
        mountPath: /srv/jupyterhub/options_form_config.json
        subPath: options_form_config.json
      - name: swan-jh
        mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/1_swan_config.py
        subPath: swan_config.py
      - name: swan-jh
        mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/2_swan_spark_config.py
        subPath: swan_spark_config.py
      - name: swan-secrets
        mountPath: /srv/jupyterhub/private/eos.cred
        subPath: eos.cred
      - name: swan-secrets
        mountPath: /srv/jupyterhub/private/hadoop.cred
        subPath: hadoop.cred
      - name: swan-secrets
        mountPath: /srv/jupyterhub/private/sparkk8s.cred
        subPath: sparkk8s.cred
      - name: swan-cull-scripts
        mountPath: /srv/jupyterhub/culler/check_ticket.sh
        subPath: cull_check_ticket.sh
      - name: swan-cull-scripts
        mountPath: /srv/jupyterhub/culler/delete_ticket.sh
        subPath: cull_delete_ticket.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/eos_token.sh
        subPath: eos_token.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/hadoop_token.sh
        subPath: hadoop_token.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/webhdfs_token.sh
        subPath: webhdfs_token.sh
      - name: swan-tokens-scripts
        mountPath: /srv/jupyterhub/private/sparkk8s_token.sh
        subPath: sparkk8s_token.sh
      - name: cvmfs-sft-cern-ch
        mountPath: /cvmfs/sft.cern.ch
    extraVolumes:
      - name: cvmfs-sft-cern-ch
        persistentVolumeClaim:
          claimName: cvmfs-sft-cern-ch-pvc
      - name: swan-jh
        configMap:
          name: swan-scripts
          items:
          - key: options_form_config.json
            path: options_form_config.json
          - key: swan_config.py
            path: swan_config.py
          - key: swan_spark_config.py
            path: swan_spark_config.py
      - name: swan-cull-scripts
        configMap:
          name: swan-scripts
          items:
          - key: cull_check_ticket.sh
            path: cull_check_ticket.sh
          - key: cull_delete_ticket.sh
            path: cull_delete_ticket.sh
          defaultMode: 356 # 0544 perm
      - name: swan-tokens-scripts
        configMap:
          name: swan-scripts-env-prod
          items:
          - key: hadoop_token.sh
            path: hadoop_token.sh
          - key: webhdfs_token.sh
            path: webhdfs_token.sh
          - key: eos_token.sh
            path: eos_token.sh
          - key: sparkk8s_token.sh
            path: sparkk8s_token.sh
          defaultMode: 356 # 0544 perm
      - name: swan-secrets
        secret:
          secretName: swan
          items:
          - key: eos.cred
            path: eos.cred
          - key: hadoop.cred
            path: hadoop.cred
          - key: sparkk8s.cred
            path: sparkk8s.cred
    config:
      KeyCloakAuthenticator:
        oidc_issuer: https://auth.cern.ch/auth/realms/cern
        admin_role: swan-admins
        scope:
          - profile
          - email
          - offline_access
        exchange_tokens:
          - eos-service
          - cernbox-service
        logout_redirect_uri: https://cern.ch/swan
        auto_login: True
        username_key: preferred_username
        client_id: # placeholder, check secrets
        client_secret: # placeholder, check secrets
        oauth_callback_url: # placeholder, check secrets
      JupyterHub:
        authenticator_class: keycloakauthenticator.KeyCloakAuthenticator
    extraConfig:
      00-authConf: |
        def pre_spawn_hook(authenticator, spawner, auth_state):
          spawner.environment['ACCESS_TOKEN'] = auth_state['exchanged_tokens']['eos-service']
          spawner.environment['OAUTH_INSPECTION_ENDPOINT'] = authenticator.userdata_url.replace('https://', '')
          spawner.user_uid = str(str(auth_state['oauth_user']['cern_uid'])) # k8s only supports values as strings!
          decoded_token = authenticator._decode_token(auth_state['access_token'])
          spawner.user_roles = authenticator.claim_roles_key(authenticator, decoded_token)
        c.KeyCloakAuthenticator.pre_spawn_hook = pre_spawn_hook
      # TODO delete this once we upgrade to newer upstream (which loads files from this path automatically)
      01-swanConf: |
        exec(open('/usr/local/etc/jupyterhub/jupyterhub_config.d/1_swan_config.py').read())
      # TODO move this into separate chart
      # TODO delete this once we upgrade to newer upstream (which loads files from this path automatically)
      10-sparkConf: |
        exec(open('/usr/local/etc/jupyterhub/jupyterhub_config.d/2_swan_spark_config.py').read()) 
        c.SwanKubeSpawner.modify_pod_hook = spark_modify_pod_hook
    extraEnv:
      # placeholder for hub auth state cryptographic key
      JUPYTERHUB_CRYPT_KEY:
    db:
      type: postgres
      # placeholder for postgres connection url
      url: 
      # placeholder for postgres password
      password:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/path: /hub/metrics
    networkPolicy:
      enabled: false
    # placeholder for hub cookieSecret
    cookieSecret:
  rbac:
    enabled: true
  scheduling:
    userScheduler:
      enabled: false
    podPriority:
      enabled: false
  prePuller:
    hook:
      enabled: true
    continuous:
      enabled: false
  debug:
    enabled: true
  # disable upstream cull, but enable custom one
  cull:
    enabled: false
  custom:
    cull:
      enabled: true
      period: 600
      checkEosAuth:
        enabled: true
    cvmfs:
      storageProvisioner: csi-cvmfsplugin
      repositories:
        - sft.cern.ch
        - sft-nightlies.cern.ch
        - alice.cern.ch
        - alice-ocdb.cern.ch
        - alice-nightlies.cern.ch
        - atlas.cern.ch
        - atlas-condb.cern.ch
        - atlas-nightlies.cern.ch
        - cms.cern.ch
        - cms-ib.cern.ch
        - cms-bril.cern.ch
        - lhcb.cern.ch
        - lhcb-condb.cern.ch
        - lhcbdev.cern.ch
        - fcc.cern.ch
        - geant4.cern.ch
        - clicbp.cern.ch
        - ams.cern.ch
        - compass.cern.ch
        - compass-condb.cern.ch
        - na62.cern.ch
        - ganga.cern.ch
        - na61.cern.ch
        - projects.cern.ch
        - alpha.cern.ch
        - cvmfs-config.cern.ch
        - sw.hsf.org
      prefetcher:
        enabled: false
        image:
          name: "gitlab-registry.cern.ch/swan/docker-images/cvmfs-prefetcher"
          tag: "v1.1"
# placeholders for swan credentials
swan:
  secrets:
    eos:
      cred:
    hadoop:
      cred:
    sparkk8s:
      cred:
    ingress:
      cert:
      key:
