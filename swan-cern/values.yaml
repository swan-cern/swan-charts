swan:
  cvmfs:
    deployDaemonSet: &cvmfsDeployDS true
    deployCsiDriver: &cvmfsDeployCSI false
    useCsiDriver: &cvmfsUseCSI false
    prefetcher:
      enabled: true
      jobs:
        # ROOT
        cron_opennotebook_root_kernel:
          command: >-
            source /cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-centos7-gcc11-opt/setup.sh &&
            (timeout 20s python3 -m JupyROOT.kernel.rootkernel > /dev/null 2>&1 || true)
          minute: '*/15'
        # NXCALS
        cron_opennotebook_nxcals:
          command: >-
            source /cvmfs/sft.cern.ch/lcg/views/LCG_105a_nxcals_pro/x86_64-centos7-gcc11-opt/setup.sh &&
            (timeout 20s python3 -m ipykernel > /dev/null 2>&1 || true) &&
            (timeout 20s python3 -c 'import pyspark' || true)
          minute: '*/15'
        # CUDA
        cron_opennotebook_cuda:
          command: >-
            (lsmod | grep nvidia) &&
            source /cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-centos7-gcc11-opt/setup.sh &&
            (timeout 20s python3 -c 'import tensorflow' || true) &&
            (timeout 20s python3 -c 'import torch' || true)
          minute: '*/15'
    repositories:
      - cvmfs-config.cern.ch
      - sft.cern.ch
      - sft-nightlies.cern.ch
      - alice.cern.ch
      - alice-ocdb.cern.ch
      - alice-nightlies.cern.ch
      - alpha.cern.ch
      - ams.cern.ch
      - atlas.cern.ch
      - atlas-condb.cern.ch
      - atlas-nightlies.cern.ch
      - clicbp.cern.ch
      - cms.cern.ch
      - cms-ib.cern.ch
      - cms-bril.cern.ch
      - compass.cern.ch
      - compass-condb.cern.ch
      - fcc.cern.ch
      - ganga.cern.ch
      - geant4.cern.ch
      - lhcb.cern.ch
      - lhcb-condb.cern.ch
      - lhcbdev.cern.ch
      - na61.cern.ch
      - na62.cern.ch
      - projects.cern.ch
      - ship.cern.ch
      - sw.hsf.org
      - sndlhc.cern.ch
    resources:
      requests:
        memory: 1.5G
  eos:
    deployDaemonSet: &eosDeployDS false
    deployCsiDriver: &eosDeployCSI true
    useCsiDriver: &eosUseCSI true
  eosxd:
    resources:
      requests:
        memory: 1.5G
  jupyterhub:
    singleuser:
      cpu:
        guarantee: 0.5
    scheduling:
      userPods:
        nodeAffinity:
          matchNodePurpose: ignore
    hub:
      extraVolumeMounts:
        - name: swan-jh-cern
          mountPath: /srv/jupyterhub/options_form_config.json
          subPath: options_form_config.json
        - name: swan-jh
          mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/1_swan_config.py
          subPath: swan_config.py
        - name: swan-jh-cern
          mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/2_swan_config_cern.py
          subPath: swan_config_cern.py
        - name: swan-jh-cern
          mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/3_swan_computing_config.py
          subPath: swan_computing_config.py
        - name: swan-secrets
          mountPath: /srv/jupyterhub/private/eos.cred
          subPath: eos.cred
        - name: swan-secrets
          mountPath: /srv/jupyterhub/private/hadoop.cred
          subPath: hadoop.cred
        - name: swan-secrets
          mountPath: /srv/jupyterhub/private/sparkk8s.cred
          subPath: sparkk8s.cred
        - name: cvmfs
          mountPath: /cvmfs
      extraVolumes:
        - name: cvmfs
          hostPath:
            path: /var/cvmfs
            type: Directory
        - name: swan-jh
          configMap:
            name: swan-scripts
            items:
            - key: swan_config.py
              path: swan_config.py
        - name: swan-jh-cern
          configMap:
            name: swan-scripts-cern
            items:
            - key: options_form_config.json
              path: options_form_config.json
            - key: swan_config_cern.py
              path: swan_config_cern.py
            - key: swan_computing_config.py
              path: swan_computing_config.py
        - name: swan-secrets
          secret:
            secretName: swan-cern
            items:
            - key: eos.cred
              path: eos.cred
            - key: hadoop.cred
              path: hadoop.cred
            - key: sparkk8s.cred
              path: sparkk8s.cred
      config:
        KeyCloakAuthenticator:
          oidc_issuer: https://auth.cern.ch/auth/realms/cern
          admin_role: swan-admins
          exchange_tokens:
            - eos-service
            - cernbox-service
          logout_redirect_url: https://cern.ch/swan
          auto_login: False
          username_claim: preferred_username
          client_id: # placeholder, check secrets
          client_secret: # placeholder, check secrets
          oauth_callback_url: # placeholder, check secrets
          # skip refreshing tokens if already refreshed in last 110 minutes
          # this assumes tokens provided by keycloak are valid for 120 minutes
          auth_refresh_age: 6600
          refresh_pre_spawn: False
        JupyterHub:
          allow_named_servers: False
        SwanKubeSpawner:
          # memory request for user pod (fraction of the limit)
          mem_request_fraction: 0.6
      extraConfig:
        00-authConf: |
          def pre_spawn_hook(authenticator, spawner, auth_state):
            spawner.environment['ACCESS_TOKEN'] = auth_state['exchanged_tokens']['eos-service']
            spawner.environment['OAUTH_INSPECTION_ENDPOINT'] = authenticator.userdata_url.replace('https://', '')
            spawner.user_uid = str(str(auth_state['oauth_user']['cern_uid'])) # k8s only supports values as strings!
            decoded_token = authenticator._decode_token(auth_state['access_token'])
            spawner.user_roles = authenticator.claim_roles_key(authenticator, decoded_token)
          c.KeyCloakAuthenticator.pre_spawn_hook = pre_spawn_hook
        02-spawnError: |
          SPAWN_ERROR_MESSAGE = """SWAN could not start a session for your user, please try again. If the problem persists, please check:
          <ul>
              <li>Do you have a CERNBox account? If not, click <a href="https://cernbox.cern.ch" target="_blank">here</a>.</li>
              <li>If you requested a GPU, are all of them busy? Please ask <a href="https://cern.service-now.com/service-portal?id=functional_element&name=swan" target="_blank">SWAN Support</a>.</li>
              <li>Is there a problem with the service? Find information <a href="https://cern.service-now.com/service-portal?id=service_status_board" target="_blank">here</a>.</li>
              <li>If none of the options apply, please open a <a href="https://cern.service-now.com/service-portal?id=functional_element&name=swan" target="_blank">Support Ticket</a>.</li>
          </ul>"""

          # SWAN@CERN error message
          c.SpawnHandlersConfigs.spawn_error_message = SPAWN_ERROR_MESSAGE
      db:
        type: postgres
        # placeholder for postgres connection url
        url:
        # placeholder for postgres password
        password:
      services:
        hadoop-token-generator: {} # apiToken is generated by the chart
        prometheus-service-monitor: {} # apiToken is generated by the chart
      loadRoles:
        prometheus:
          description: Access to hub Prometheus metrics
          scopes: ['read:metrics']
          services: [prometheus-service-monitor]
    custom:
      cull:
        # 4 hours
        timeout: 14400
        checkEosAuth: true
        hooksDir: /srv/jupyterhub/culler
      cvmfs:
        deployDaemonSet: *cvmfsDeployDS
        deployCsiDriver: *cvmfsDeployCSI
        useCsiDriver: *cvmfsUseCSI
        repositories:
          - mount: cvmfs-config.cern.ch
          - mount: sft.cern.ch
            proxy: 'http://ca-proxy-sft.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: sft-nightlies.cern.ch
            proxy: 'http://ca-proxy-sft.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: alice.cern.ch
            proxy: 'http://ca-proxy-alice.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: alice-ocdb.cern.ch
            proxy: 'http://ca-proxy-alice.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: alice-nightlies.cern.ch
            proxy: 'http://ca-proxy-alice.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: alpha.cern.ch
          - mount: ams.cern.ch
          - mount: atlas.cern.ch
            proxy: 'http://ca-proxy-atlas.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: atlas-condb.cern.ch
            proxy: 'http://ca-proxy-atlas.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: atlas-nightlies.cern.ch
            proxy: 'http://ca-proxy-atlas.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: clicbp.cern.ch
          - mount: cms.cern.ch
            proxy: 'http://cmsmeyproxy.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: cms-ib.cern.ch
            proxy: 'http://cmsmeyproxy.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: cms-bril.cern.ch
            proxy: 'http://cmsmeyproxy.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: compass.cern.ch
            proxy: 'http://ca-proxy-compass.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: compass-condb.cern.ch
            proxy: 'http://ca-proxy-compass.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: fcc.cern.ch
          - mount: ganga.cern.ch
          - mount: geant4.cern.ch
          - mount: lhcb.cern.ch
            proxy: 'http://ca-proxy-lhcb.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: lhcb-condb.cern.ch
            proxy: 'http://ca-proxy-lhcb.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: lhcbdev.cern.ch
            proxy: 'http://ca-proxy-lhcb.cern.ch:3128;http://ca-proxy.cern.ch:3128'
          - mount: na61.cern.ch
          - mount: na62.cern.ch
          - mount: projects.cern.ch
          - mount: sw.hsf.org
      eos:
        deployDaemonSet: *eosDeployDS
        deployCsiDriver: *eosDeployCSI
        useCsiDriver: *eosUseCSI
      spark:
        configurationPath: /cvmfs/sft.cern.ch/lcg/etc/hadoop-confext
swanCern:
  secrets:
    eos:
      cred:
    hadoop:
      cred:
    sparkk8s:
      cred:

hadoopTokenGenerator:
  image: gitlab-registry.cern.ch/swan/docker-images/hadoop-token-generator:v3.0.3

fluentd:
  caCertPath: &fluentdCaCertPath /etc/ssl/ca-bundle.crt
  plugins:
    - fluent-plugin-rewrite-tag-filter
    - fluent-plugin-out-http
    - fluent-plugin-grok-parser
    - fluent-plugin-route
  containerRuntime: containerd
  output:
    includeInternal: false
    cacert: *fluentdCaCertPath
  configMapConfigs:
    - fluentd-prometheus-conf # Preserve prometheus config for probes to work
    - fluentd-sources-conf
    - fluentd-filters-conf
    - fluentd-outputs-conf
  fileConfigs:
    # This is to disable the configuration that comes from upstream
    01_sources.conf: "" 
    02_filters.conf: ""
    03_dispatch.conf: ""
    04_outputs.conf: ""
  volumeMounts:
  - name: ca-certificate
    mountPath: *fluentdCaCertPath
    subPath: ca-bundle.crt
    readOnly: true
  volumes:
  - name: ca-certificate
    configMap:
      name: fluentd-ca
      items:
        - key: ca-bundle.crt
          path: ca-bundle.crt

gpu-operator:
  enabled: true
  validator:
    repository: registry.cern.ch/magnum
    version: v22.9.1
  operator:
    repository: registry.cern.ch/magnum
    version: v22.9.1
    defaultRuntime: containerd
    initContainer:
      repository: registry.cern.ch/magnum
      version: 11.4.2-base-ubi8
  driver:
    repository: registry.cern.ch/swan
    image: gpu-driver
    version: "525.125.06-cuda12.0.0-5.19.9-200.fc36.x86_64"
    imagePullPolicy: Always
    manager:
      repository: registry.cern.ch/magnum
      version: v0.6.0
    licensingConfig:
      configMapName: "nvidia-grid-license"
    kernelModuleConfig:
      name: kernel-module-params
  vgpuManager:
    driverManager:
      repository: registry.cern.ch
      version: v0.5.1
  vfioManager:
    repository: registry.cern.ch
    version: 11.7.1-base-ubi8
  vgpuDeviceManager:
    repository: registry.cern.ch
    version: v0.2.0
  toolkit:
    repository: registry.cern.ch/magnum
    version: v1.11.0
  devicePlugin:
    repository: registry.cern.ch/magnum
    version: v0.13.0
  dcgm:
    repository: registry.cern.ch
    version: 3.1.3-1-ubuntu20.04
  dcgmExporter:
    enabled: true
    repository: registry.cern.ch/magnum
    version: 3.1.3-3.1.2-ubuntu20.04
    config:
      name: nvidia-dcgm-exporter-metrics
  gfd:
    repository: registry.cern.ch/magnum
    version: v0.7.0
  mig:
    strategy: mixed
  migManager:
    repository: registry.cern.ch/magnum
    version: v0.5.0
    config:
      name: nvidia-mig-config
  nodeStatusExporter:
    repository: registry.cern.ch
    version: v22.9.1
  sandboxDevicePlugin:
    repository: registry.cern.ch/magnum
    version: v1.2.1
  devicePlugin:
    repository: registry.cern.ch/magnum
    version: v0.12.2-ubi8
    config:
      name: nvidia-time-slicing-config
  node-feature-discovery:
    image:
      repository: registry.cern.ch/magnum/node-feature-discovery
      tag: v0.10.1

