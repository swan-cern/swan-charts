global:
  # These are placeholders for the LCG values defined in the GitOps repository
  generic:
    lcg: 
    platform: 
  cuda:
    lcg: 
    platform: 
  nxcals:
    lcg: 
    platform:

user-image:
  name:  &userImageName "gitlab-registry.cern.ch/swan/docker-images/jupyter/swan-cern"
  tag: &userImageTag "v0.0.21"

swan:
  cvmfs-csi:
    extraConfigMaps:
      cvmfs-csi-default-local:
        default.local: |
          CVMFS_HTTP_PROXY="http://ca-proxy.cern.ch:3128"
          CVMFS_QUOTA_LIMIT=20000
          CVMFS_CACHE_BASE=/cvmfs-localcache
    automountDaemonUnmountTimeout: 1800
    cvmfs-csi-config-d:
      sft.cern.ch.conf: |
        CVMFS_HTTP_PROXY='http://ca-proxy-sft.cern.ch:3128;http://ca-proxy.cern.ch:3128'
    nodeplugin:
      prefetcher:
        enabled: true
        # Ensure the warmup cronjobs run with the same image as the user
        image:
          repository: *userImageName
          tag: *userImageTag
        # Jobs to warmup ROOT, NXCALS and CUDA stacks respectively
        jobs:
          - name: cron-warmup-lcg-releases
            schedule: "*/15 * * * *"
            script: |-
              #!/bin/bash

              source /cvmfs/sft.cern.ch/lcg/views/{{ .Values.global.generic.lcg }}/{{ .Values.global.generic.platform }}/setup.sh &&
              (timeout 20s python3 -m ipykernel > /dev/null 2>&1 || true)

              source /cvmfs/sft.cern.ch/lcg/views/{{ .Values.global.generic.lcg }}/{{ .Values.global.generic.platform }}/setup.sh &&
              (timeout 20s python3 -m JupyROOT.kernel.rootkernel > /dev/null 2>&1 || true)

              source /cvmfs/sft.cern.ch/lcg/views/{{ .Values.global.nxcals.lcg }}/{{ .Values.global.nxcals.platform }}/setup.sh &&
              (timeout 20s python3 -m ipykernel > /dev/null 2>&1 || true) &&
              (timeout 20s python3 -c 'import pyspark' || true)

              (lsmod | grep nvidia) &&
              source /cvmfs/sft.cern.ch/lcg/views/{{ .Values.global.cuda.lcg }}/{{ .Values.global.cuda.platform }}/setup.sh &&
              (timeout 20s python3 -c 'import tensorflow' || true) &&
              (timeout 20s python3 -c 'import torch' || true)

  eos:
    deployDaemonSet: &eosDeployDS false
    deployCsiDriver: &eosDeployCSI true
    useCsiDriver: &eosUseCSI true
  eosxd:
    resources:
      requests:
        memory: 1.5G
  jupyterhub:
    singleuser:
      cpu:
        guarantee: 0.5
      image:
        name: *userImageName
        tag: *userImageTag
    scheduling:
      userPods:
        nodeAffinity:
          matchNodePurpose: ignore
    hub:
      extraVolumeMounts:
        - name: swan-jh-cern
          mountPath: /srv/jupyterhub/options_form_config.json
          subPath: options_form_config.json
        - name: swan-jh
          mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/1_swan_config.py
          subPath: swan_config.py
        - name: swan-jh-cern
          mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/2_swan_config_cern.py
          subPath: swan_config_cern.py
        - name: swan-jh-cern
          mountPath: /usr/local/etc/jupyterhub/jupyterhub_config.d/3_swan_computing_config.py
          subPath: swan_computing_config.py
        - name: swan-secrets
          mountPath: /srv/jupyterhub/private/eos.cred
          subPath: eos.cred
        - name: swan-secrets
          mountPath: /srv/jupyterhub/private/hadoop.cred
          subPath: hadoop.cred
        - name: swan-secrets
          mountPath: /srv/jupyterhub/private/sparkk8s.cred
          subPath: sparkk8s.cred
        - name: cvmfs
          mountPath: /cvmfs
          mountPropagation: HostToContainer
      extraVolumes:
        - name: cvmfs
          persistentVolumeClaim:
            claimName: cvmfs
        - name: swan-jh
          configMap:
            name: swan-scripts
            items:
            - key: swan_config.py
              path: swan_config.py
        - name: swan-jh-cern
          configMap:
            name: swan-scripts-cern
            items:
            - key: options_form_config.json
              path: options_form_config.json
            - key: swan_config_cern.py
              path: swan_config_cern.py
            - key: swan_computing_config.py
              path: swan_computing_config.py
        - name: swan-secrets
          secret:
            secretName: swan-cern
            items:
            - key: eos.cred
              path: eos.cred
            - key: hadoop.cred
              path: hadoop.cred
            - key: sparkk8s.cred
              path: sparkk8s.cred
      config:
        KeyCloakAuthenticator:
          oidc_issuer: https://auth.cern.ch/auth/realms/cern
          admin_role: swan-admins
          exchange_tokens:
            - eos-service
            - cernbox-service
          logout_redirect_url: https://cern.ch/swan
          auto_login: False
          username_claim: preferred_username
          client_id: # placeholder, check secrets
          client_secret: # placeholder, check secrets
          oauth_callback_url: # placeholder, check secrets
          # skip refreshing tokens if already refreshed in last 110 minutes
          # this assumes tokens provided by keycloak are valid for 120 minutes
          auth_refresh_age: 6600
          refresh_pre_spawn: False
        JupyterHub:
          allow_named_servers: False
        SwanKubeSpawner:
          # memory request for user pod (fraction of the limit)
          mem_request_fraction: 0.6
      extraConfig:
        00-authConf: |
          def pre_spawn_hook(authenticator, spawner, auth_state):
            spawner.environment['ACCESS_TOKEN'] = auth_state['exchanged_tokens']['eos-service']
            spawner.environment['OAUTH_INSPECTION_ENDPOINT'] = authenticator.userdata_url.replace('https://', '')
            spawner.user_uid = str(str(auth_state['oauth_user']['cern_uid'])) # k8s only supports values as strings!
            decoded_token = authenticator._decode_token(auth_state['access_token'])
            spawner.user_roles = authenticator.claim_roles_key(authenticator, decoded_token)
          c.KeyCloakAuthenticator.pre_spawn_hook = pre_spawn_hook
        02-spawnError: |
          SPAWN_ERROR_MESSAGE = """SWAN could not start a session for your user, please try again. If the problem persists, please check:
          <ul>
              <li>Do you have a CERNBox account? If not, click <a href="https://cernbox.cern.ch" target="_blank">here</a>.</li>
              <li>If you requested a GPU, are all of them busy? Please ask <a href="https://cern.service-now.com/service-portal?id=functional_element&name=swan" target="_blank">SWAN Support</a>.</li>
              <li>Is there a problem with the service? Find information <a href="https://cern.service-now.com/service-portal?id=service_status_board" target="_blank">here</a>.</li>
              <li>If none of the options apply, please open a <a href="https://cern.service-now.com/service-portal?id=functional_element&name=swan" target="_blank">Support Ticket</a>.</li>
          </ul>"""

          # SWAN@CERN error message
          c.SpawnHandlersConfigs.spawn_error_message = SPAWN_ERROR_MESSAGE
      db:
        type: postgres
        # placeholder for postgres connection url
        url:
        # placeholder for postgres password
        password:
      services:
        hadoop-token-generator: {} # apiToken is generated by the chart
        prometheus-service-monitor: {} # apiToken is generated by the chart
      loadRoles:
        prometheus:
          description: Access to hub Prometheus metrics
          scopes: ['read:metrics']
          services: [prometheus-service-monitor]
    custom:
      cull:
        # 4 hours
        timeout: 14400
        checkEosAuth: true
        hooksDir: /srv/jupyterhub/culler
      eos:
        deployDaemonSet: *eosDeployDS
        deployCsiDriver: *eosDeployCSI
        useCsiDriver: *eosUseCSI
      spark:
        configurationPath: /cvmfs/sft.cern.ch/lcg/etc/hadoop-confext
swanCern:
  secrets:
    eos:
      cred:
    hadoop:
      cred:
    sparkk8s:
      cred:

hadoopTokenGenerator:
  image: gitlab-registry.cern.ch/swan/docker-images/hadoop-token-generator:v3.0.3

fluentd:
  caCertPath: &fluentdCaCertPath /etc/ssl/ca-bundle.crt
  plugins:
    - fluent-plugin-rewrite-tag-filter
    - fluent-plugin-out-http
    - fluent-plugin-grok-parser
    - fluent-plugin-route
  containerRuntime: containerd
  output:
    includeInternal: false
    cacert: *fluentdCaCertPath
  configMapConfigs:
    - fluentd-prometheus-conf # Preserve prometheus config for probes to work
    - fluentd-sources-conf
    - fluentd-filters-conf
    - fluentd-outputs-conf
  fileConfigs:
    # This is to disable the configuration that comes from upstream
    01_sources.conf: "" 
    02_filters.conf: ""
    03_dispatch.conf: ""
    04_outputs.conf: ""
  volumeMounts:
  - name: ca-certificate
    mountPath: *fluentdCaCertPath
    subPath: ca-bundle.crt
    readOnly: true
  volumes:
  - name: ca-certificate
    configMap:
      name: fluentd-ca
      items:
        - key: ca-bundle.crt
          path: ca-bundle.crt

gpu-operator:
  enabled: true
  validator:
    repository: registry.cern.ch/kubernetes
    version: v22.9.1
  operator:
    repository: registry.cern.ch/kubernetes
    version: v22.9.1
    defaultRuntime: containerd
    initContainer:
      repository: registry.cern.ch/kubernetes
      version: 11.4.2-base-ubi8
  driver:
    repository: registry.cern.ch/kubernetes
    image: nvidia-gpu-driver
    version: "v550.54.15-6.6.13-200.fc39.x86_64"
    imagePullPolicy: Always
    manager:
      repository: registry.cern.ch/kubernetes
      version: v0.6.0
    licensingConfig:
      configMapName: "nvidia-grid-license"
    kernelModuleConfig:
      name: kernel-module-params
  vgpuManager:
    repository: registry.cern.ch
    driverManager:
      repository: registry.cern.ch
      version: v0.5.1
  vfioManager:
    repository: registry.cern.ch
    version: 11.7.1-base-ubi8
    driverManager:
      repository: registry.cern.ch
      version: v0.5.1
  vgpuDeviceManager:
    repository: registry.cern.ch
    version: v0.2.0
  toolkit:
    repository: registry.cern.ch/kubernetes
    version: v1.11.0
  devicePlugin:
    repository: registry.cern.ch/kubernetes
    version: v0.13.0
  dcgm:
    repository: registry.cern.ch
    version: 3.1.3-1-ubuntu20.04
  dcgmExporter:
    repository: registry.cern.ch/kubernetes
    version: 3.1.3-3.1.2-ubuntu20.04
    config:
      name: nvidia-dcgm-exporter-metrics
  gfd:
    repository: registry.cern.ch/kubernetes
    version: v0.7.0
  mig:
    strategy: mixed
  migManager:
    repository: registry.cern.ch/kubernetes
    version: v0.5.0
    config:
      name: nvidia-mig-config
  nodeStatusExporter:
    repository: registry.cern.ch
    version: v22.9.1
  sandboxDevicePlugin:
    repository: registry.cern.ch/kubernetes
    version: v1.2.1
  devicePlugin:
    repository: registry.cern.ch/kubernetes
    version: v0.12.2-ubi8
    config:
      name: nvidia-time-slicing-config
  node-feature-discovery:
    image:
      repository: registry.cern.ch/kubernetes/node-feature-discovery
      tag: v0.10.1

